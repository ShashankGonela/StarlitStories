# LangGraph Configuration
# If using LangGraph Cloud/Runtime, provide your API key here
LANGGRAPH_API_KEY=your_langgraph_api_key_here

# LangSmith Tracing Configuration
# Enable tracing to monitor LLM calls, tool invocations, and API endpoints
LANGCHAIN_TRACING_V2=true
LANGCHAIN_API_KEY=your_langsmith_api_key_here
LANGCHAIN_PROJECT=Starlit Stories
LANGCHAIN_ENDPOINT=https://api.smith.langchain.com

# LLM Provider Configuration
# Choose your provider and add the appropriate API key below

# For Google Gemini (recommended for this project)
GEMINI_API_KEY=your_google_gemini_api_key_here

# For OpenAI (alternative)
# OPENAI_API_KEY=your_openai_api_key_here

# For Anthropic Claude (alternative)
# ANTHROPIC_API_KEY=your_anthropic_api_key_here

# Runtime Provider (maps model names to actual provider)
# Options: "gemini", "openai", "anthropic"
LANGGRAPH_RUNTIME_PROVIDER=gemini

# Story Generation Settings
MAX_STORY_ITERATIONS=3
DEFAULT_STORY_LENGTH=medium  # short, medium, or long
LOG_LEVEL=INFO

# Safety Settings
ENABLE_SAFETY_CHECKS=true
STRICT_MODE=true
